{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%cd scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T06:40:26.417400Z",
     "iopub.status.busy": "2023-07-13T06:40:26.417242Z",
     "iopub.status.idle": "2023-07-13T06:40:26.428582Z",
     "shell.execute_reply": "2023-07-13T06:40:26.427990Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T06:40:26.430818Z",
     "iopub.status.busy": "2023-07-13T06:40:26.430522Z",
     "iopub.status.idle": "2023-07-13T06:40:27.436429Z",
     "shell.execute_reply": "2023-07-13T06:40:27.435960Z"
    }
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import os\n",
    "\n",
    "import graph_tool.all as gt\n",
    "import matplotlib\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import hypergeom, pearsonr\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from functions import *\n",
    "\n",
    "\n",
    "# Graph-Tool compatibility\n",
    "plt.switch_backend('cairo')\n",
    "\n",
    "# Style\n",
    "sns.set_theme(context='talk', style='white', palette='Set2')\n",
    "plt.rcParams.update({\n",
    "    'pdf.fonttype': 42,\n",
    "    'ps.fonttype': 42,\n",
    "    'font.size': 22,\n",
    "    'axes.titlesize': 'medium',\n",
    "    'axes.labelsize': 'large',\n",
    "    'xtick.labelsize': 'medium',\n",
    "    'ytick.labelsize': 'medium',\n",
    "    'legend.fontsize': 'medium',\n",
    "    'legend.title_fontsize': 'medium',\n",
    "    'figure.titlesize': 'x-large',\n",
    "})\n",
    "\n",
    "# Figure transparency\n",
    "# matplotlib.rcParams['figure.facecolor'] = (1., 0., 0., 0.3)  # Debugging\n",
    "matplotlib.rcParams['figure.facecolor'] = (1., 0., 0., 0.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 1022/1022 [00:15<00:00, 64.77it/s]\n"
     ]
    }
   ],
   "source": [
    "# Integrity check\n",
    "check_ct_edge_specificity()  # Check for duplicate edges with different attentions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata\n",
    "meta = get_meta()\n",
    "\n",
    "# Subject preview\n",
    "filtered = []\n",
    "for i, row in meta.iterrows():\n",
    "    try:\n",
    "        load_graph_by_id(row['SubID'])\n",
    "        assert not np.isnan(row['nps_MoodDysCurValue'])  # Has NPS information available\n",
    "        assert row['BRAAK_AD'] in (6,) and row['CERAD'] in (4,) and row['CDRScore'] in (3,)\n",
    "    except:\n",
    "        continue\n",
    "    filtered.append(f'{row[\"SubID\"]} {row[\"Ethnicity\"]} {row[\"Sex\"]}, {row[\"Age\"]}, BRAAK {row[\"BRAAK_AD\"]}, CERAD {row[\"CERAD\"]}, CDR {row[\"CDRScore\"]}, {row[\"Dx\"]}')\n",
    "filtered = np.sort(filtered)\n",
    "for i in range(len(filtered)):\n",
    "    # print(filtered[i])\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = './attentions.pkl'\n",
    "if os.path.isfile(fname):\n",
    "    # Load data\n",
    "    with open('./attentions.pkl', 'rb') as f:\n",
    "        all_data = pickle.load(f)\n",
    "    attention_stack, all_edges, columns, subject_ids = all_data['data'], all_data['edges'], all_data['heads'], all_data['subject_ids']\n",
    "\n",
    "else:\n",
    "    # Parameters\n",
    "    # Scaled probably shouldn't be used, but better for visualization\n",
    "    # until results are more even\n",
    "    columns = get_attention_columns(scaled=False)\n",
    "    subject_ids = meta['SubID'].to_numpy()\n",
    "\n",
    "    # Load graphs\n",
    "    graphs, subject_ids = load_many_graphs(subject_ids, column=columns)\n",
    "    # graphs = [compute_graph(g) for g in graphs]\n",
    "\n",
    "    # # Get attentions\n",
    "    # df = {}\n",
    "    # for column in get_attention_columns():\n",
    "    #     attention, _ = compute_edge_summary(graphs, subject_ids=subject_ids)\n",
    "    #     attention = attention.set_index('Edge')\n",
    "    #     df[column] = attention.var(axis=1)\n",
    "\n",
    "\n",
    "    # Set indices to edges and clean\n",
    "    print('Fixing indices...')\n",
    "    for i in tqdm(range(len(graphs))):\n",
    "        graphs[i].index = graphs[i].apply(lambda r: get_edge_string([r['TF'], r['TG']]), axis=1)\n",
    "        graphs[i] = graphs[i].drop(columns=['TF', 'TG'])\n",
    "        # Remove duplicates\n",
    "        graphs[i] = graphs[i][~graphs[i].index.duplicated(keep='first')]\n",
    "\n",
    "    # Get all unique edges\n",
    "    print('Getting unique edges...')\n",
    "    all_edges = np.unique(sum([list(g.index) for g in graphs], []))\n",
    "\n",
    "\n",
    "    # Standardize index order\n",
    "    print('Standardizing indices...')\n",
    "    for i in tqdm(range(len(graphs))):\n",
    "        # Add missing indices and order based on `all_edges`\n",
    "        # to_add = [edge for edge in all_edges if edge not in list(graphs[i].index)]  # SLOW\n",
    "        to_add = list(set(all_edges) - set(graphs[i].index))\n",
    "\n",
    "        # Empty rows\n",
    "        new_rows = pd.DataFrame(\n",
    "            [[np.nan]*len(graphs[i].columns)]*len(to_add),\n",
    "            columns=graphs[i].columns,\n",
    "        ).set_index(pd.Series(to_add))\n",
    "        # Native concat\n",
    "        graphs[i] = pd.concat([graphs[i], new_rows]).loc[all_edges]\n",
    "\n",
    "    # Convert to numpy\n",
    "    graphs = [g.to_numpy() for g in graphs]\n",
    "    attention_stack = np.stack(graphs, axis=-1)\n",
    "    # attention_stack.shape = (Edge, Head, Subject)\n",
    "    # attention_stack.shape = (all_edges, columns, subject_ids)\n",
    "\n",
    "    # Save all data\n",
    "    all_data = {'data': attention_stack, 'edges': all_edges, 'heads': columns, 'subject_ids': subject_ids}\n",
    "    # np.savez('attentions.npz', **all_data)\n",
    "    with open(fname, 'wb') as f:\n",
    "        pickle.dump(\n",
    "            all_data,\n",
    "            f,\n",
    "            protocol=pickle.HIGHEST_PROTOCOL,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional useful parameters\n",
    "self_loops = [split_edge_string(s)[0] == split_edge_string(s)[1] for s in all_edges]\n",
    "self_loops = np.array(self_loops)\n",
    "# Remove self loops\n",
    "all_edges = all_edges[~self_loops]\n",
    "attention_stack = attention_stack[~self_loops]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available attention columns: ['AD_imp_1', 'AD_imp_2', 'SCZ_imp_1', 'SCZ_imp_2', 'data_imp_1', 'data_imp_2', 'data_imp_3', 'data_imp_4']\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "print(f'\\nAvailable attention columns: {get_attention_columns()}')\n",
    "column_ad = get_attention_columns()[0]\n",
    "column_scz = get_attention_columns()[2]\n",
    "column_data = get_attention_columns()[4]\n",
    "synthetic_nodes_of_interest = ['OPC', 'Micro', 'Oligo']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intra-Contrast Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure parameters\n",
    "param = {\n",
    "    'subjects': ['M31969', 'M20337'],\n",
    "    'columns': [column_data, column_ad, column_scz],\n",
    "    'column_names': ['Data-Driven', 'AD-Prior', 'SCZ-Prior'],\n",
    "    'column_groups': [get_attention_columns()[4:8], get_attention_columns()[:2], get_attention_columns()[2:4]],\n",
    "    'column_group_names': ['Data Prioritization', 'AD Prioritization', 'SCZ Prioritization'],\n",
    "    'ancestries': meta.groupby('Ethnicity').count()['SubID'].sort_values().index[::-1].to_list()[:3] + ['all'],\n",
    "    'contrast': 'c15x',\n",
    "}\n",
    "\n",
    "# Generate palette\n",
    "palette = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "param['palette'] = {sid: rgba_to_hex(palette[i]) for i, sid in enumerate(param['subjects'])}\n",
    "\n",
    "# Preview subjects\n",
    "for sid in param['subjects']:\n",
    "    row = meta.loc[meta['SubID']==sid].iloc[0]\n",
    "    # print(f'{row[\"SubID\"]} {row[\"Ethnicity\"]} {row[\"Sex\"]}, {row[\"Age\"]}, BRAAK {row[\"BRAAK_AD\"]}, CERAD {row[\"CERAD\"]}, CDR {row[\"CDRScore\"]}, {row[\"Dx\"]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subplot layout (doesn't work well with constrained layout)\n",
    "# NOTE: This cannot be used, as constrained layout has glitches\n",
    "# (see https://github.com/matplotlib/matplotlib/issues/23290)\n",
    "# with uneven mosaics\n",
    "# fig, axs = get_mosaic(shape, figsize=(int((3/2) * shape_array.shape[1]), int((3/2) * shape_array.shape[0])), constrained_layout=False)\n",
    "\n",
    "# Subfigure layout (longer)\n",
    "# NOTE: Constrained layout will fail for all\n",
    "# subplots if a single one is not able to scale.\n",
    "# Also, sometimes leaving a subfigure blank will\n",
    "# cause it to fail, especially if on an edge.\n",
    "# It is VERY finnicky.\n",
    "# SOLUTION: Save again using `fig.savefig(...)`\n",
    "# and it will run without warning.  Then, you\n",
    "# can visually inspect for scaling issues.\n",
    "# fig, axs = create_subfigure_mosaic(shape_array)\n",
    "# fig.set_constrained_layout_pads(w_pad=0, h_pad=0, wspace=.4, hspace=.4)  # *_pad is pad for figs (including subfigs), *_space is pad between subplots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge Prioritization and Cross-Ancestry Enrichment - Figure 5cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Edge Discovery Enrichment (None, None, None, N)\n",
      "Prioritization Ranges [[14.0, 22.0], [22.0, 49.0], [49.0, 680.0]]\n",
      "Filtered 165669 edges of 204507 total from histogram\n",
      "Prioritization Ranges [[9.0, 13.0], [13.0, 25.0], [25.0, 104.0]]\n",
      "Filtered 52826 edges of 61429 total from histogram\n",
      "Prioritization Ranges [[8.0, 11.0], [11.0, 21.0], [21.0, 88.0]]\n",
      "Filtered 46979 edges of 53899 total from histogram\n",
      "Prioritization Ranges [[15.0, 23.0], [23.0, 51.0], [51.0, 875.0]]\n",
      "Filtered 195859 edges of 242486 total from histogram\n",
      "\n",
      "Ancestry Enrichment Comparison (R)\n",
      "Index(['AFR_data_imp_1', 'AMR_data_imp_1', 'EUR_data_imp_1', 'all_data_imp_1'], dtype='object', name='Ancestry')\n",
      "Index(['EUR', 'AFR', 'AMR', 'all'], dtype='object')\n",
      "Index(['EUR', 'AFR', 'AMR'], dtype='object')\n",
      "\n",
      "Saving Figure...\n"
     ]
    }
   ],
   "source": [
    "shape = \"\"\"\n",
    "    NNNNNNNNNNN\n",
    "    NNNNNNNNNNN\n",
    "    NNNNNNNNNNN\n",
    "    NNNNNNNNNNN\n",
    "    RRRRRRRRRRR\n",
    "    RRRRRRRRRRR\n",
    "    RRRRRRRRRRR\n",
    "    RRRRRRRRRRR\n",
    "    RRRRRRRRRRR\n",
    "    RRRRRRRRRRR\n",
    "    RRRRRRRRRRR\n",
    "\"\"\"\n",
    "fig, axs = create_subfigure_mosaic(shape_array_from_shape(shape))\n",
    "\n",
    "axs_lab = (len(param['ancestries']) - 1) * ['None'] + ['N']\n",
    "# axs_lab = ['K', 'L', 'M', 'N']\n",
    "print(f'\\nEdge Discovery Enrichment ({\", \".join(axs_lab)})')\n",
    "for ancestry, ax in zip(param['ancestries'], [axs[lab] if lab in axs else None for lab in axs_lab]):\n",
    "    # Filter to ancestry\n",
    "    anc_data = all_data.copy()\n",
    "    if ancestry != 'all':\n",
    "        sub_ids = meta.loc[meta['Ethnicity'] == ancestry, 'SubID'].to_list()\n",
    "        mask = [sid in sub_ids for sid in anc_data['subject_ids']]\n",
    "        anc_data['data'] = anc_data['data'][:, :, mask]\n",
    "        anc_data['subject_ids'] = np.array(anc_data['subject_ids'])[mask]\n",
    "\n",
    "    # Run\n",
    "    temp = plot_edge_discovery_enrichment(\n",
    "        **anc_data,\n",
    "        column=param['columns'][0],\n",
    "        range_colors=[rgb_to_float(hex_to_rgb('#7aa457')), rgb_to_float(hex_to_rgb('#a46cb7')), rgb_to_float(hex_to_rgb('#cb6a49'))],\n",
    "        ax=ax,\n",
    "        postfix=f'{ancestry}_{param[\"columns\"][0]}',\n",
    "        gene_max_num=300,\n",
    "        threshold=95,\n",
    "        clamp_min=4,\n",
    "        skip_plot=(ax is None),\n",
    "        verbose=True)\n",
    "    if ax is not None:\n",
    "        ax.set_xlabel(f'High-Scoring Edges ({param[\"column_names\"][0]})')\n",
    "        ylabel = 'Frequency'\n",
    "        if ancestry != 'all': ylabel += f' ({ancestry})'\n",
    "        ax.set_ylabel(ylabel)\n",
    "    # MANUAL PROCESSING\n",
    "    # Run the output '../plots/genes_<column>.csv' from above on Metascape as multiple gene list and perform\n",
    "    # enrichment.  From the all-in-one ZIP file, save the file from Enrichment_GO/GO_membership.csv as '../plots/go_<column>.csv'\n",
    "    # and rerun.\n",
    "\n",
    "axs_lab = ['R']\n",
    "print(f'\\nAncestry Enrichment Comparison ({\", \".join(axs_lab)})')\n",
    "postfixes = [f'{ancestry}_{param[\"columns\"][0]}' for ancestry in param['ancestries']]\n",
    "enrichments = plot_cross_enrichment(postfixes, names=param['ancestries'], ax=axs[axs_lab[0]], excluded_subgroups=['all'])\n",
    "\n",
    "# Place labels\n",
    "offset = plot_labels(axs, shape=shape)\n",
    "\n",
    "# Save figure\n",
    "print('\\nSaving Figure...')\n",
    "fig.savefig(f'../plots/figure_5_main.pdf', bbox_inches='tight', pad_inches=1, format='pdf', transparent=True, backend='cairo')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRS Analyses - Figure 6a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PRS Analysis (S, U)\n",
      "\n",
      "Saving Figure...\n"
     ]
    }
   ],
   "source": [
    "# SCZ\n",
    "# Data\n",
    "# AD\n",
    "# SCZ\n",
    "shape = \"\"\"\n",
    "    SSSSSSSSSSSSSSSUUUUUUUUUUUUUUU\n",
    "    SSSSSSSSSSSSSSSUUUUUUUUUUUUUUU\n",
    "    SSSSSSSSSSSSSSSUUUUUUUUUUUUUUU\n",
    "    SSSSSSSSSSSSSSSUUUUUUUUUUUUUUU\n",
    "\"\"\"\n",
    "fig, axs = create_subfigure_mosaic(shape_array_from_shape(shape))\n",
    "\n",
    "# Plot all panels\n",
    "axs_lab = ['S', 'U']\n",
    "print(f'\\nPRS Analysis ({\", \".join(axs_lab)})')\n",
    "# Takes around an hour for each loop with no subsampling (on first run)\n",
    "for fname, head_prefix, ylabel, prs_col, ax_idx in zip(\n",
    "    ('ad_prs_df.csv', 'scz_prs_df.csv'),\n",
    "    ('_'.join(column_ad.split('_')[:-1]), '_'.join(column_scz.split('_')[:-1])),\n",
    "    ('AD Importance Score', 'SCZ Importance Score'),\n",
    "    ('prs_scaled_AD_Bellenguez', 'prs_scaled_SCZ.3.5_MVP'),\n",
    "    axs_lab\n",
    "):\n",
    "    df = pd.read_csv(fname, index_col=0) if os.path.isfile(fname) else None\n",
    "    covariates = get_genotype_meta()[['SubID', 'imp_sex_score'] + [f'imp_anc_PC{i}' for i in range(1, 7)] + [f'imp_anc_{anc}' for anc in ('AFR', 'AMR', 'EAS', 'EUR')]]\n",
    "    df, prs_df, axs[ax_idx] = plot_prs_correlation(\n",
    "        meta, **all_data, ax=axs[ax_idx],\n",
    "        df=df, num_targets=5, ylabel=ylabel, max_scale=False,\n",
    "        head_prefix=head_prefix, prs_col=prs_col,\n",
    "        covariates=covariates, subsample=1)\n",
    "    if not os.path.isfile(fname): df.to_csv(fname)\n",
    "\n",
    "# Place labels\n",
    "offset = plot_labels(axs, shape=shape)\n",
    "\n",
    "# Save figure\n",
    "print('\\nSaving Figure...')\n",
    "fig.savefig(f'../plots/figure_6_prs.pdf', bbox_inches='tight', pad_inches=1, format='pdf', transparent=True, backend='cairo')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
